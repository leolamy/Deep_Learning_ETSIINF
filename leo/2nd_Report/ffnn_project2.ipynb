{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "QYuALZOG-AMq",
        "tags": []
      },
      "source": [
        "## Assignment: Image recognition\n",
        "- Alumno 1:\n",
        "- Alumno 2:\n",
        "- Alumno 3:\n",
        "\n",
        "The goals of the assignment are:\n",
        "* Develop proficiency in using Tensorflow/Keras for training Neural Nets (NNs).\n",
        "* Put into practice the acquired knowledge to optimize the parameters and architecture of a feedforward Neural Net (ffNN), in the context of an image recognition problem.\n",
        "* Put into practice NNs specially conceived for analysing images. Design and optimize the parameters of a Convolutional Neural Net (CNN) to deal with previous task.\n",
        "* Train popular architectures from scratch (e.g., GoogLeNet, VGG, ResNet, ...), and compare the results with the ones provided by their pre-trained versions using transfer learning.\n",
        "\n",
        "Follow the link below to download the classification data set  “xview_recognition”: [https://drive.upm.es/s/2DDPE2zHw5dbM3G](https://drive.upm.es/s/2DDPE2zHw5dbM3G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:03:21.559788Z",
          "iopub.status.busy": "2026-02-15T16:03:21.559193Z",
          "iopub.status.idle": "2026-02-15T16:04:20.201785Z",
          "shell.execute_reply": "2026-02-15T16:04:20.200294Z",
          "shell.execute_reply.started": "2026-02-15T16:03:21.559726Z"
        },
        "id": "6U41pnVrpwbd",
        "outputId": "38b8381c-5937-4080-84d2-41295211a526",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUCCÈS : Fichier trouvé à : ./xview_recognition/xview_ann_train.json\n",
            "Base de données chargée avec succès !\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "url = 'https://drive.upm.es/s/2DDPE2zHw5dbM3G/download'\n",
        "zip_name = 'dataset.zip'\n",
        "\n",
        "r = requests.get(url, stream=True)\n",
        "with open(zip_name, 'wb') as f:\n",
        "    for chunk in r.iter_content(chunk_size=1024):\n",
        "        f.write(chunk)\n",
        "\n",
        "if os.path.getsize(zip_name) < 10000:\n",
        "    print(f\"ERREUR : Le fichier {zip_name} est trop petit. Le lien est invalide ou nécessite une connexion.\")\n",
        "else:\n",
        "    with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "        z.extractall(\".\")\n",
        "\n",
        "    target_file = 'xview_ann_train.json'\n",
        "    found_path = None\n",
        "\n",
        "    for root, dirs, files in os.walk(\".\"):\n",
        "        if target_file in files:\n",
        "            found_path = os.path.join(root, target_file)\n",
        "            break\n",
        "\n",
        "    if found_path:\n",
        "        print(f\"SUCCÈS : Fichier trouvé à : {found_path}\")\n",
        "\n",
        "        import json\n",
        "        json_file = found_path\n",
        "\n",
        "        with open(json_file) as ifs:\n",
        "            json_data = json.load(ifs)\n",
        "        print(\"Base de données chargée avec succès !\")\n",
        "\n",
        "    else:\n",
        "        print(f\"ERREUR : {target_file} reste introuvable après extraction.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:21.031186Z",
          "start_time": "2024-10-26T00:00:17.131476Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:20.204413Z",
          "iopub.status.busy": "2026-02-15T16:04:20.203973Z",
          "iopub.status.idle": "2026-02-15T16:04:20.213333Z",
          "shell.execute_reply": "2026-02-15T16:04:20.212075Z",
          "shell.execute_reply.started": "2026-02-15T16:04:20.204367Z"
        },
        "id": "kIvtyEfkpwbf",
        "outputId": "33c94fa1-7989-4673-f893-452d9a846927",
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU non détecté. Activez l'accélérateur dans les réglages du notebook.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Vérifie la présence de processeurs graphiques\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if gpus:\n",
        "    try:\n",
        "        # Configuration pour ne pas allouer toute la mémoire d'un coup\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"GPU activé : {len(gpus)} processeur(s) détecté(s)\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"GPU non détecté. Activez l'accélérateur dans les réglages du notebook.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:21.066937Z",
          "start_time": "2024-10-26T00:00:21.059126Z"
        },
        "editable": true,
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:20.214920Z",
          "iopub.status.busy": "2026-02-15T16:04:20.214571Z",
          "iopub.status.idle": "2026-02-15T16:04:20.226716Z",
          "shell.execute_reply": "2026-02-15T16:04:20.225853Z",
          "shell.execute_reply.started": "2026-02-15T16:04:20.214893Z"
        },
        "id": "OYtqD3Oh-AMw",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "import numpy as np\n",
        "\n",
        "class GenericObject:\n",
        "    \"\"\"\n",
        "    Generic object data.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.id = uuid.uuid4()\n",
        "        self.bb = (-1, -1, -1, -1)\n",
        "        self.category= -1\n",
        "        self.score = -1\n",
        "\n",
        "class GenericImage:\n",
        "    \"\"\"\n",
        "    Generic image data.\n",
        "    \"\"\"\n",
        "    def __init__(self, filename):\n",
        "        self.filename = filename\n",
        "        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n",
        "        self.objects = list([])\n",
        "\n",
        "    def add_object(self, obj: GenericObject):\n",
        "        self.objects.append(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:21.153693Z",
          "start_time": "2024-10-26T00:00:21.149079Z"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:20.229137Z",
          "iopub.status.busy": "2026-02-15T16:04:20.228759Z",
          "iopub.status.idle": "2026-02-15T16:04:20.244834Z",
          "shell.execute_reply": "2026-02-15T16:04:20.243883Z",
          "shell.execute_reply.started": "2026-02-15T16:04:20.229110Z"
        },
        "id": "I_GygShu-AMz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "categories = {0: 'Cargo plane', 1: 'Small car', 2: 'Bus', 3: 'Truck', 4: 'Motorboat', 5: 'Fishing vessel', 6: 'Dump truck', 7: 'Excavator', 8: 'Building', 9: 'Helipad', 10: 'Storage tank', 11: 'Shipping container', 12: 'Pylon'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:20.247049Z",
          "iopub.status.busy": "2026-02-15T16:04:20.246194Z",
          "iopub.status.idle": "2026-02-15T16:04:24.143468Z",
          "shell.execute_reply": "2026-02-15T16:04:24.142391Z",
          "shell.execute_reply.started": "2026-02-15T16:04:20.247017Z"
        },
        "id": "LGYyCbE9pwbg",
        "outputId": "8008d1e0-deec-42d9-9c63-312c217f261a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.5.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2026.1.4)\n",
            "Requirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.3.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:21.292654Z",
          "start_time": "2024-10-26T00:00:21.205321Z"
        },
        "editable": true,
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:24.145822Z",
          "iopub.status.busy": "2026-02-15T16:04:24.145376Z",
          "iopub.status.idle": "2026-02-15T16:04:24.154522Z",
          "shell.execute_reply": "2026-02-15T16:04:24.153304Z",
          "shell.execute_reply.started": "2026-02-15T16:04:24.145774Z"
        },
        "id": "fRBA7ReQ-AM0",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import rasterio\n",
        "import numpy as np\n",
        "\n",
        "def load_geoimage(filename):\n",
        "    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n",
        "    src_raster = rasterio.open('./xview_recognition/'+filename, 'r')\n",
        "    # RasterIO to OpenCV (see inconsistencies between libjpeg and libjpeg-turbo)\n",
        "    input_type = src_raster.profile['dtype']\n",
        "    input_channels = src_raster.count\n",
        "    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n",
        "    for band in range(input_channels):\n",
        "        img[:, :, band] = src_raster.read(band+1)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diNBB3qy-AM2"
      },
      "source": [
        "#### Training\n",
        "Design and train a ffNN to deal with the “xview_recognition” classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:21.416449Z",
          "start_time": "2024-10-26T00:00:21.311510Z"
        },
        "editable": true,
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:24.156866Z",
          "iopub.status.busy": "2026-02-15T16:04:24.155978Z",
          "iopub.status.idle": "2026-02-15T16:04:24.307009Z",
          "shell.execute_reply": "2026-02-15T16:04:24.306095Z",
          "shell.execute_reply.started": "2026-02-15T16:04:24.156823Z"
        },
        "id": "Orto292C-AM3",
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load database\n",
        "json_file = './xview_recognition/xview_ann_train.json'\n",
        "with open(json_file) as ifs:\n",
        "    json_data = json.load(ifs)\n",
        "ifs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:22.874518Z",
          "start_time": "2024-10-26T00:00:22.204948Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:24.308711Z",
          "iopub.status.busy": "2026-02-15T16:04:24.308225Z",
          "iopub.status.idle": "2026-02-15T16:04:25.580618Z",
          "shell.execute_reply": "2026-02-15T16:04:25.579715Z",
          "shell.execute_reply.started": "2026-02-15T16:04:24.308595Z"
        },
        "id": "4GjFLHs4-AM4",
        "outputId": "a0fbc2dd-13f2-48b9-e7c6-5bd68193ee97",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Cargo plane': 635, 'Small car': 3324, 'Bus': 1768, 'Truck': 2210, 'Motorboat': 1069, 'Fishing vessel': 706, 'Dump truck': 1236, 'Excavator': 789, 'Building': 3594, 'Helipad': 111, 'Storage tank': 1469, 'Shipping container': 1523, 'Pylon': 312}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "counts = dict.fromkeys(categories.values(), 0)\n",
        "anns = []\n",
        "for json_img, json_ann in zip(json_data['images'].values(), json_data['annotations'].values()):\n",
        "    image = GenericImage(json_img['filename'])\n",
        "    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n",
        "    obj = GenericObject()\n",
        "    obj.bb = (int(json_ann['bbox'][0]), int(json_ann['bbox'][1]), int(json_ann['bbox'][2]), int(json_ann['bbox'][3]))\n",
        "    obj.category = json_ann['category_id']\n",
        "    # Resampling strategy to reduce training time\n",
        "    counts[obj.category] += 1\n",
        "    image.add_object(obj)\n",
        "    anns.append(image)\n",
        "print(counts)\n",
        "labels = [img.objects[0].category for img in anns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:23.656800Z",
          "start_time": "2024-10-26T00:00:23.123245Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:25.582375Z",
          "iopub.status.busy": "2026-02-15T16:04:25.581801Z",
          "iopub.status.idle": "2026-02-15T16:04:25.665367Z",
          "shell.execute_reply": "2026-02-15T16:04:25.664368Z",
          "shell.execute_reply.started": "2026-02-15T16:04:25.582346Z"
        },
        "id": "NriAECvS-AM6",
        "outputId": "912fa056-e600-4732-c214-6a60c7069500",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training images: 16871\n",
            "Number of validation images: 1875\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "anns_train, anns_valid = train_test_split(anns, test_size=0.1, random_state=1, shuffle=True, stratify=labels)\n",
        "print('Number of training images: ' + str(len(anns_train)))\n",
        "print('Number of validation images: ' + str(len(anns_valid)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:25.056806Z",
          "start_time": "2024-10-26T00:00:24.261581Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:25.668844Z",
          "iopub.status.busy": "2026-02-15T16:04:25.668415Z",
          "iopub.status.idle": "2026-02-15T16:04:25.882949Z",
          "shell.execute_reply": "2026-02-15T16:04:25.882220Z",
          "shell.execute_reply.started": "2026-02-15T16:04:25.668816Z"
        },
        "id": "BNkjbY2e-AM7",
        "outputId": "ca2ed7de-f975-426f-a11c-e00eac8bdf9e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ random_flip (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,583,936</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,325</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ random_flip (\u001b[38;5;33mRandomFlip\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │    \u001b[38;5;34m12,583,936\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │        \u001b[38;5;34m13,325\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,655,053</span> (52.09 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,655,053\u001b[0m (52.09 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,650,957</span> (52.07 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,650,957\u001b[0m (52.07 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> (16.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,096\u001b[0m (16.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Input, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import CategoricalFocalCrossentropy\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(32, 32, 3)))\n",
        "model.add(tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"))\n",
        "model.add(tf.keras.layers.RandomRotation(0.25))  # 0.25 = 90°\n",
        "model.add(Flatten())\n",
        "\n",
        "# Layer 1 : Réduit à 512 pour éviter l'explosion de paramètres (Overfitting)\n",
        "model.add(Dense(1024, kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('swish'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Layer 2\n",
        "model.add(Dense(1024, kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('swish'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Layer 3\n",
        "#model.add(Dense(256, kernel_initializer='he_normal', kernel_regularizer=l2(0.002)))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Activation('swish'))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "# Output\n",
        "model.add(Dense(len(categories)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:25.467525Z",
          "start_time": "2024-10-26T00:00:25.434068Z"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:25.884253Z",
          "iopub.status.busy": "2026-02-15T16:04:25.884006Z",
          "iopub.status.idle": "2026-02-15T16:04:25.888390Z",
          "shell.execute_reply": "2026-02-15T16:04:25.887603Z",
          "shell.execute_reply.started": "2026-02-15T16:04:25.884228Z"
        },
        "id": "-aSlKtG6-AM7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.optimizers import Adam\n",
        "#\n",
        "## Learning rate is changed to 0.001\n",
        "#opt = Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999, epsilon=1e-8, amsgrad=True, clipnorm=1.0)\n",
        "#model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:26.254555Z",
          "start_time": "2024-10-26T00:00:26.243908Z"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:25.890637Z",
          "iopub.status.busy": "2026-02-15T16:04:25.889812Z",
          "iopub.status.idle": "2026-02-15T16:04:25.903990Z",
          "shell.execute_reply": "2026-02-15T16:04:25.903145Z",
          "shell.execute_reply.started": "2026-02-15T16:04:25.890611Z"
        },
        "id": "GGAJEfpB-AM8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import TerminateOnNaN, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "# Supprimer ReduceLROnPlateau si CosineDecay est utilisé\n",
        "\n",
        "terminate = TerminateOnNaN()\n",
        "\n",
        "callbacks = [model_checkpoint, early_stop, terminate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:25.905701Z",
          "iopub.status.busy": "2026-02-15T16:04:25.905264Z",
          "iopub.status.idle": "2026-02-15T16:04:25.925245Z",
          "shell.execute_reply": "2026-02-15T16:04:25.924079Z",
          "shell.execute_reply.started": "2026-02-15T16:04:25.905663Z"
        },
        "id": "rn9VGYDGpwbi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generator_images(objs, batch_size, do_shuffle=False):\n",
        "    while True:\n",
        "        working = list(objs)  # copie, jamais de mutation\n",
        "        if do_shuffle:\n",
        "            np.random.shuffle(working)\n",
        "        groups = [working[i:i+batch_size] for i in range(0, len(working), batch_size)]\n",
        "        for group in groups:\n",
        "            images, labels = [], []\n",
        "            for (filename, obj) in group:\n",
        "                img = load_geoimage(filename)\n",
        "                img_tensor = tf.convert_to_tensor(img)\n",
        "                img_tensor = tf.image.convert_image_dtype(img_tensor, tf.float32)\n",
        "                img_resized = tf.image.resize(img_tensor, [32, 32], method='bicubic')\n",
        "                images.append(img_resized.numpy())\n",
        "                label_idx = list(categories.keys())[list(categories.values()).index(obj.category)]\n",
        "                one_hot = tf.keras.utils.to_categorical(label_idx, num_classes=len(categories))\n",
        "                labels.append(one_hot)\n",
        "            yield np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate the list of objects from annotations\n",
        "objs_train = [(ann.filename, obj) for ann in anns_train for obj in ann.objects]\n",
        "objs_valid = [(ann.filename, obj) for ann in anns_valid for obj in ann.objects]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# labels_train = liste des catégories pour chaque objet dans objs_train\n",
        "labels_train = [obj.category for (_, obj) in objs_train]\n",
        "classes = np.array(sorted(set(labels_train)))\n",
        "\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels_train)\n",
        "class_weight_dict = dict(zip(classes, weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-26T00:00:27.058834Z",
          "start_time": "2024-10-26T00:00:27.022627Z"
        },
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:25.926885Z",
          "iopub.status.busy": "2026-02-15T16:04:25.926526Z",
          "iopub.status.idle": "2026-02-15T16:04:25.962418Z",
          "shell.execute_reply": "2026-02-15T16:04:25.961575Z",
          "shell.execute_reply.started": "2026-02-15T16:04:25.926844Z"
        },
        "id": "Yht-QqUH-AM8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generators\n",
        "batch_size = 128 # change to 32 to stabilize the gradients\n",
        "train_generator = generator_images(objs_train, batch_size, do_shuffle=True)\n",
        "valid_generator = generator_images(objs_valid, batch_size, do_shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsZlfHwFc7FK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "counts_array = np.array([counts[categories[i]] for i in range(len(categories))], dtype=np.float32)\n",
        "alpha_per_class = 1.0 / counts_array\n",
        "alpha_per_class = alpha_per_class / alpha_per_class.sum()\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=100 * (len(objs_train) // 128)\n",
        ")\n",
        "optimizer = Nadam(learning_rate=lr_schedule, weight_decay=1e-4)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=CategoricalFocalCrossentropy(alpha=alpha_per_class.tolist(), gamma=2.0),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-10-26T00:00:27.913670Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "execution": {
          "iopub.execute_input": "2026-02-15T16:04:25.964369Z",
          "iopub.status.busy": "2026-02-15T16:04:25.963610Z",
          "iopub.status.idle": "2026-02-15T17:26:04.754014Z",
          "shell.execute_reply": "2026-02-15T17:26:04.750887Z",
          "shell.execute_reply.started": "2026-02-15T16:04:25.964331Z"
        },
        "id": "TrfpdECs-AM9",
        "jupyter": {
          "is_executing": true
        },
        "outputId": "ad5ac088-0212-4dcc-9395-e227d66475be",
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model\n",
            "Epoch 1/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.2943 - loss: 0.4366 - val_accuracy: 0.3168 - val_loss: 0.4272\n",
            "Epoch 2/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.4161 - loss: 0.3069 - val_accuracy: 0.3787 - val_loss: 0.3510\n",
            "Epoch 3/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.4654 - loss: 0.2741 - val_accuracy: 0.4277 - val_loss: 0.3043\n",
            "Epoch 4/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.4803 - loss: 0.2592 - val_accuracy: 0.3941 - val_loss: 0.3576\n",
            "Epoch 5/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.4995 - loss: 0.2454 - val_accuracy: 0.4389 - val_loss: 0.3038\n",
            "Epoch 6/100\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.5210 - loss: 0.2347 - val_accuracy: 0.4523 - val_loss: 0.2956\n",
            "Epoch 7/100\n",
            "\u001b[1m 83/132\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 861ms/step - accuracy: 0.5310 - loss: 0.2261"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "print('Training model')\n",
        "epochs = 100 # model still improving after 20 epochs -> stabilization\n",
        "train_steps = math.ceil(len(objs_train)/batch_size)\n",
        "valid_steps = math.ceil(len(objs_valid)/batch_size)\n",
        "h = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_steps,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    #class_weight=class_weight_dict, \n",
        "    verbose=1\n",
        ")# Best validation model\n",
        "best_idx = int(np.argmin(h.history['val_loss']))\n",
        "best_value = np.min(h.history['val_loss'])\n",
        "print('Best validation model: epoch ' + str(best_idx+1), ' - val_loss ' + str(best_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "8IMMO_mT-AM9",
        "tags": []
      },
      "source": [
        "#### Validation\n",
        "Compute validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T17:26:04.760990Z",
          "iopub.status.busy": "2026-02-15T17:26:04.760199Z",
          "iopub.status.idle": "2026-02-15T17:26:04.797664Z",
          "shell.execute_reply": "2026-02-15T17:26:04.796502Z",
          "shell.execute_reply.started": "2026-02-15T17:26:04.760932Z"
        },
        "id": "HAanJ-V0-AM1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def draw_confusion_matrix(cm, categories):\n",
        "    # Draw confusion matrix\n",
        "    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n",
        "    ax = fig.add_subplot(111)\n",
        "    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.colormaps['Blues'])\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=list(categories.values()), yticklabels=list(categories.values()), ylabel='Annotation', xlabel='Prediction')\n",
        "    # Rotate the tick labels and set their alignment\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "    # Loop over data dimensions and create text annotations\n",
        "    thresh = cm.max() / 2.0\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T17:42:50.187660Z",
          "iopub.status.busy": "2026-02-15T17:42:50.186674Z",
          "iopub.status.idle": "2026-02-15T17:46:08.818853Z",
          "shell.execute_reply": "2026-02-15T17:46:08.817397Z",
          "shell.execute_reply.started": "2026-02-15T17:42:50.187623Z"
        },
        "id": "pjVniKBGpwbj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "model.load_weights('model.keras')\n",
        "y_true, y_pred = [], []\n",
        "all_images = []\n",
        "temp_true_labels = []\n",
        "\n",
        "print(\"Chargement des données de validation...\")\n",
        "for ann in anns_valid:\n",
        "    # 1. Charger l'image brute\n",
        "    image_raw = load_geoimage(ann.filename)\n",
        "\n",
        "    # 2. Prétraitement IDENTIQUE à l'entraînement\n",
        "    image_tensor = tf.convert_to_tensor(image_raw)\n",
        "    image_tensor = tf.image.convert_image_dtype(image_tensor, tf.float32)\n",
        "    # C'est cette ligne qui manquait :\n",
        "    image_resized = tf.image.resize(image_tensor, [32, 32], method='bicubic')\n",
        "\n",
        "    # Stocker pour chaque objet de l'image\n",
        "    for obj_pred in ann.objects:\n",
        "        all_images.append(image_resized.numpy())\n",
        "        temp_true_labels.append(obj_pred.category)\n",
        "\n",
        "if all_images:\n",
        "    X_valid = np.array(all_images)\n",
        "    print(f\"Lancement de la prédiction sur {len(X_valid)} objets...\")\n",
        "\n",
        "    all_predictions = model.predict(X_valid, batch_size=64, verbose=1)\n",
        "\n",
        "    category_names = list(categories.values())\n",
        "    for i in range(len(all_predictions)):\n",
        "        pred_category = category_names[np.argmax(all_predictions[i])]\n",
        "        y_true.append(temp_true_labels[i])\n",
        "        y_pred.append(pred_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T17:46:14.945405Z",
          "iopub.status.busy": "2026-02-15T17:46:14.944912Z",
          "iopub.status.idle": "2026-02-15T17:46:16.002677Z",
          "shell.execute_reply": "2026-02-15T17:46:16.001562Z",
          "shell.execute_reply.started": "2026-02-15T17:46:14.945372Z"
        },
        "id": "u-_9onKYpwbj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(categories.values()))\n",
        "draw_confusion_matrix(cm, categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T17:46:32.057083Z",
          "iopub.status.busy": "2026-02-15T17:46:32.055883Z",
          "iopub.status.idle": "2026-02-15T17:46:32.071220Z",
          "shell.execute_reply": "2026-02-15T17:46:32.070019Z",
          "shell.execute_reply.started": "2026-02-15T17:46:32.057049Z"
        },
        "id": "YKS8hszopwbj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute the accuracy\n",
        "correct_samples_class = np.diag(cm).astype(float)\n",
        "total_samples_class = np.sum(cm, axis=1).astype(float)\n",
        "total_predicts_class = np.sum(cm, axis=0).astype(float)\n",
        "print('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\n",
        "acc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\n",
        "print('Mean Recall: %.3f%%' % (acc.mean() * 100))\n",
        "acc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\n",
        "print('Mean Precision: %.3f%%' % (acc.mean() * 100))\n",
        "for idx in range(len(categories)):\n",
        "    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n",
        "    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n",
        "    tp = cm[idx, idx]\n",
        "    fp = sum(cm[:, idx]) - tp\n",
        "    fn = sum(cm[idx, :]) - tp\n",
        "    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n",
        "    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n",
        "    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n",
        "    # Precision: proportion of predicted positive cases that were truly real positives.\n",
        "    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n",
        "    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n",
        "    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n",
        "    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n",
        "    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n",
        "    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n",
        "    print('> %s: Recall: %.3f%% Precision: %.3f%% Specificity: %.3f%% Dice: %.3f%%' % (list(categories.values())[idx], recall*100, precision*100, specificity*100, f1_score*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm9Fb45Hpwbk"
      },
      "source": [
        "#### Testing\n",
        "Try to improve the results provided in the competition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T17:46:54.507413Z",
          "iopub.status.busy": "2026-02-15T17:46:54.506272Z",
          "iopub.status.idle": "2026-02-15T17:46:54.577459Z",
          "shell.execute_reply": "2026-02-15T17:46:54.576277Z",
          "shell.execute_reply.started": "2026-02-15T17:46:54.507378Z"
        },
        "id": "tJr_-xCt-AM-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "anns = []\n",
        "root_dir = './xview_recognition/'\n",
        "test_dir = os.path.join(root_dir, 'xview_test')\n",
        "for (dirpath, dirnames, filenames) in os.walk(test_dir):\n",
        "    for filename in filenames:\n",
        "        rel_dir = os.path.relpath(dirpath, root_dir)\n",
        "        clean_filename = os.path.join(rel_dir, filename)\n",
        "        image = GenericImage(clean_filename)\n",
        "        image.tile = np.array([0, 0, 224, 224])\n",
        "        obj = GenericObject()\n",
        "        obj.bb = (0, 0, 224, 224)\n",
        "        obj.category = os.path.basename(dirpath)\n",
        "        image.add_object(obj)\n",
        "        anns.append(image)\n",
        "print('Number of testing images: ' + str(len(anns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T17:48:10.990881Z",
          "iopub.status.busy": "2026-02-15T17:48:10.989451Z",
          "iopub.status.idle": "2026-02-15T17:52:26.540733Z",
          "shell.execute_reply": "2026-02-15T17:52:26.539635Z",
          "shell.execute_reply.started": "2026-02-15T17:48:10.990824Z"
        },
        "id": "TGs2zqfv-AM_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "model.load_weights('model.keras')\n",
        "predictions_data = {\"images\": {}, \"annotations\": {}}\n",
        "all_test_images = []\n",
        "metadata = [] # Pour stocker (image_id, bbox) dans le même ordre que les images\n",
        "ann_id = 0\n",
        "\n",
        "print(\"Préparation des images de test...\")\n",
        "for idx, ann in enumerate(anns):\n",
        "    image_data = {\n",
        "        \"image_id\": ann.filename.split('/')[-1],\n",
        "        \"filename\": ann.filename,\n",
        "        \"width\": int(ann.tile[2]),\n",
        "        \"height\": int(ann.tile[3])\n",
        "    }\n",
        "    predictions_data[\"images\"][idx] = image_data\n",
        "\n",
        "    # Prétraitement (une seule fois par image source)\n",
        "    image_raw = load_geoimage(ann.filename)\n",
        "    image_tensor = tf.convert_to_tensor(image_raw)\n",
        "    image_tensor = tf.image.convert_image_dtype(image_tensor, tf.float32)\n",
        "    image_resized = tf.image.resize(image_tensor, [64,64], method='bicubic')\n",
        "    img_final = image_resized.numpy()\n",
        "\n",
        "    for obj_pred in ann.objects:\n",
        "        all_test_images.append(img_final)\n",
        "        metadata.append({\n",
        "            \"image_id\": ann.filename.split('/')[-1],\n",
        "            \"bbox\": [int(x) for x in obj_pred.bb]\n",
        "        })\n",
        "\n",
        "# Prédiction massive sur GPU\n",
        "if all_test_images:\n",
        "    X_test = np.array(all_test_images)\n",
        "    print(f\"Prédiction en cours sur {len(X_test)} détections...\")\n",
        "\n",
        "    # Utilisation du batch_size pour saturer les T4\n",
        "    all_preds = model.predict(X_test, batch_size=128, verbose=1)\n",
        "\n",
        "    category_names = list(categories.values())\n",
        "\n",
        "    # Reconstruction du dictionnaire final\n",
        "    for i, pred in enumerate(all_preds):\n",
        "        pred_category = category_names[np.argmax(pred)]\n",
        "\n",
        "        predictions_data[\"annotations\"][ann_id] = {\n",
        "            \"image_id\": metadata[i][\"image_id\"],\n",
        "            \"category_id\": pred_category,\n",
        "            \"bbox\": metadata[i][\"bbox\"]\n",
        "        }\n",
        "        ann_id += 1\n",
        "print(\"Test terminé.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-15T18:07:57.290331Z",
          "iopub.status.busy": "2026-02-15T18:07:57.289033Z",
          "iopub.status.idle": "2026-02-15T18:07:57.337412Z",
          "shell.execute_reply": "2026-02-15T18:07:57.336319Z",
          "shell.execute_reply.started": "2026-02-15T18:07:57.290289Z"
        },
        "id": "6D1oNJEipwbk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('prediction.json', 'w') as f:\n",
        "    json.dump(predictions_data, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
